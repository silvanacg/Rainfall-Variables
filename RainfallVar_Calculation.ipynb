{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(file_path):\n",
    "    ds = pd.read_csv(file_path, header=6)\n",
    "    ds.Date_Time = pd.to_datetime(ds.Date_Time, errors = 'coerce')\n",
    "    ds = ds.set_index('Date_Time')\n",
    "    ds.index = ds.index.tz_localize(None)\n",
    "    ds = ds.sort_index()\n",
    "    ds = ds[ds.index.notna()]\n",
    "    return ds\n",
    "\n",
    "def start_end_storm(rain_data, event_date):\n",
    "    \n",
    "    timeseries_event_date = rain_data.precip_in[(rain_data.index >= event_date) & (rain_data.index <= event_date + dt.timedelta(days=1))]\n",
    " \n",
    "    rain_event_indices = timeseries_event_date[timeseries_event_date > 0].index\n",
    "    \n",
    "    if rain_event_indices.empty:\n",
    "        # if no rain on event day, return early (no storm detected)\n",
    "        return None, None, None\n",
    "    \n",
    "    # first time and last time it rained during day of event\n",
    "    \n",
    "    first_rain_datetime = rain_event_indices[0]\n",
    "    last_rain_datetime = rain_event_indices[-1]\n",
    "    \n",
    "    #starts computing for datetimes before the first time it rained on day of event\n",
    "    \n",
    "    current_datetime = first_rain_datetime\n",
    "\n",
    "    while True:\n",
    "        # Check the 8-hour block before the first datetime for rain \n",
    "        block_start_datetime = current_datetime - pd.Timedelta(hours=8)\n",
    "        block_end_datetime = current_datetime\n",
    "        block_data = rain_data[(rain_data.index >= block_start_datetime) & (rain_data.index < block_end_datetime)]\n",
    "        #print(block_data)\n",
    "    \n",
    "        if block_data.precip_in.sum() > 0:\n",
    "            # If there was rain in the block, update current_datetime\n",
    "            current_datetime = block_data[block_data.precip_in > 0].index[0]\n",
    "        else:\n",
    "        # If no rain in the block, break the loop\n",
    "            break\n",
    "        \n",
    "    first_rain_datetime = current_datetime\n",
    "     \n",
    "#__________________________\n",
    "\n",
    "    #starts computing for datetimes after last time it rained on day of event\n",
    "   \n",
    "    current_datetime = last_rain_datetime\n",
    "    \n",
    "    while True:\n",
    "        # Check the 8-hour block after the last datetime for rain\n",
    "        block_end_datetime = current_datetime + pd.Timedelta(hours=8)\n",
    "        block_start_datetime = current_datetime\n",
    "        block_data = rain_data[(rain_data.index > block_start_datetime) & (rain_data.index <= block_end_datetime)]\n",
    "    \n",
    "    #print(block_data)\n",
    "    \n",
    "        if block_data.precip_in.sum() > 0:\n",
    "            # If there was rain in the block, update current_datetime\n",
    "            current_datetime = block_data[block_data.precip_in > 0].index[-1]\n",
    "        else:\n",
    "        # If no rain in the block, break the loop\n",
    "            break\n",
    "            \n",
    "    last_rain_datetime = current_datetime\n",
    "    \n",
    "    filtered_rainstorm_data = rain_data[(rain_data.index >= first_rain_datetime ) & (rain_data.index <= last_rain_datetime)]\n",
    "    \n",
    "    return first_rain_datetime, last_rain_datetime, filtered_rainstorm_data\n",
    "\n",
    "def compute_duration_accummrain_avgintensity_mm_h(rainstorm_data):\n",
    "    \n",
    "\n",
    "    accumulated_rain = rainstorm_data.precip_in.sum()*25.4\n",
    "    duration = (rainstorm_data.index[-1] - rainstorm_data.index[0]).total_seconds() / 3600\n",
    "    average_intensity = accumulated_rain/duration\n",
    "    \n",
    "    return accumulated_rain, duration, average_intensity\n",
    "\n",
    "def compute_peakintensity_mm(rainstorm_data, frequency_minutes):\n",
    "    \n",
    "    #compute the min frequency in the rain station file to know whether peak intensity can be calculated for frequency_minutes (e.g., 15-min)\n",
    "    \n",
    "    min_frequency = pd.tseries.frequencies.to_offset(rainstorm_data.index.to_series().diff().min())\n",
    "    frequency = str(frequency_minutes)+'T'\n",
    "    \n",
    "    if min_frequency <= pd.tseries.frequencies.to_offset(frequency):\n",
    "        \n",
    "        max_acummrain = rainstorm_data.precip_in.rolling(frequency).sum().max()\n",
    "        peak_intensity = (max_acummrain *60)*25.4/frequency_minutes\n",
    "        datetime_peak_int= (rainstorm_data.precip_in.rolling(frequency).sum()).idxmax()\n",
    "        \n",
    "        return max_acummrain,peak_intensity,datetime_peak_int\n",
    "        \n",
    "    else:\n",
    "        print('Rain data frequency is' + str(min_frequency) + 'Cannot compute peak intensity')\n",
    "        return None, None, None\n",
    "    \n",
    "def compute_cummprecipitation(rain_data, storm_start, period_hours):\n",
    "    \n",
    "    #this computes antecedent rainfall for periods before the start of the storm associated with PFDF event\n",
    "    #e.g. 24 hours before a storm that triggered PFDF started\n",
    "    \n",
    "    past_datetime = storm_start - dt.timedelta(hours = period_hours)\n",
    "    acumm_rain = (rain_data.precip_in[(rain_data.index >= past_datetime) & (rain_data.index <= storm_start)]).sum() *25.4\n",
    "    print(past_datetime, acumm_rain)\n",
    "    \n",
    "    return acumm_rain\n",
    "\n",
    "def find_matching_csv(events, csv_folder_path):\n",
    "    \n",
    "    #iterate over rain station files\n",
    "    for elem in os.listdir(csv_folder_path):\n",
    "        file = os.path.join(csv_folder_path, elem)\n",
    "        print(file)\n",
    "        ds = read_csv(file)\n",
    "        station_id = ds.Station_ID[0]\n",
    "        print(station_id)\n",
    "        \n",
    "        #iterate over PFDF events\n",
    "        for i in range(len(events)):\n",
    "            event_station_id = events['Station ID'][i]\n",
    "            #print(type(event_station_id))\n",
    "            events.EVENT_DATE = pd.to_datetime(events.EVENT_DATE)\n",
    "            event_date = events['EVENT_DATE'][i]\n",
    "\n",
    "            # if the sation id matches and the PFDF event date is in the rain station file\n",
    "            if (event_station_id == str(station_id)) and (event_date.strftime('%Y%m%d') in ds.index.strftime('%Y%m%d').unique()):\n",
    "                print(f'Matching CSV found for Station ID {event_station_id} and Event Date {event_date}', i)\n",
    "                \n",
    "                #compute rainfall variables\n",
    "                first_rain_datetime, last_rain_datetime, filtered_rainstorm_data = start_end_storm(ds, event_date)\n",
    "                accumulated_rain, duration, average_intensity = compute_duration_accummrain_avgintensity_mm_h(filtered_rainstorm_data)\n",
    "                max_acummrain15m,peak_int15m, datetime_peak_int15m = compute_peakintensity_mm(filtered_rainstorm_data,15)\n",
    "                max_acummrain30m,peak_int30m,datetime_peak_int30m = compute_peakintensity_mm(filtered_rainstorm_data,30)\n",
    "                max_acummrain60m,peak_int60m,datetime_peak_int60m = compute_peakintensity_mm(filtered_rainstorm_data,60)\n",
    "                cumm_rain_24h = compute_cummprecipitation(ds, first_rain_datetime, 24)\n",
    "                cumm_rain_48h = compute_cummprecipitation(ds, first_rain_datetime, 48)\n",
    "                #print(peakint15m)\n",
    "                \n",
    "                #add results to the inventory dataframe\n",
    "                events.loc[i, 'Storm_StartDate'] = first_rain_datetime\n",
    "                events.loc[i, 'Storm_Duration'] = duration\n",
    "                events.loc[i, 'Storm_Accum'] = accumulated_rain\n",
    "                events.loc[i,'Storm_AvgIntensity']= average_intensity\n",
    "                events.loc[i, 'Peak_I15_mm/h'] = peak_int15m\n",
    "                events.loc[i, 'Peak_I30_mm/h'] = peak_int30m\n",
    "                events.loc[i, 'Peak_I60_mm/h'] = peak_int60m\n",
    "                events.loc[i, 'Peak_I15_Date'] = datetime_peak_int15m\n",
    "                events.loc[i, 'Peak_I30_Date'] = datetime_peak_int30m\n",
    "                events.loc[i, 'Peak_I60_Date'] = datetime_peak_int60m\n",
    "                events.loc[i, 'CummRain_24h'] = cumm_rain_24h\n",
    "                events.loc[i, 'CummRain_48h'] = cumm_rain_48h\n",
    "                \n",
    "\n",
    "                print(first_rain_datetime, accumulated_rain, duration, average_intensity, cumm_rain_24h, cumm_rain_48h)\n",
    "                #print(rainstorm_filtered)\n",
    "                \n",
    "    return events\n",
    "\n",
    "events_data = pd.read_csv('~/DATA/Project2/NewInventory.csv')  #file with PFDF events\n",
    "csv_folder_path = os.path.join(os.path.expanduser('~'), 'DATA/Project2/Precip_csv2/precip_csv') #directory where rain station files are stored\n",
    "\n",
    "events_newdata = find_matching_csv(events_data, csv_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save dataframe\n",
    "pd.DataFrame.to_csv(events_newdata, '/home/silvana/DATA/Project2/Rainfall_Data_New.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zarr",
   "language": "python",
   "name": "zarr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
